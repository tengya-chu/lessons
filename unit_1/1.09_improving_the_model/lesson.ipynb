{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1.9: Improving the model\n",
    "\n",
    "### Lesson Duration: 3 hours\n",
    "\n",
    "> Purpose: The purpose of this DIY (Do It Yourself) lesson is to go through the complete process of building the model and using different techniques to improve the accuracy of the model. As George Box famously said, \"All models are wrong but some are useful\".\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "After this lesson, students will be able to:\n",
    "\n",
    "- Apply a linear regression model from the beginning\n",
    "- Improve the accuracy of the model\n",
    "- Collaborate using Git and GitHub\n",
    "- Deliver impactful presentations\n",
    "\n",
    "---\n",
    "\n",
    "### Lesson 1 key concepts\n",
    "\n",
    "> :clock10: 20 mins\n",
    "\n",
    "- Revisiting the model\n",
    "- List down the followed steps\n",
    "- Spot the areas in the model where changes could be made\n",
    "- Apply the changes\n",
    "- Fit the model and check the accuracy\n",
    "- Compare the changes in the different models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~Lab | Customer Analysis Round 7~~\n",
    "\n",
    "For this lab, we still keep using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab_round7` folder.\n",
    "\n",
    "Remember the previous rounds. Follow the steps as shown in previous lectures and try to improve the accuracy of the model. Include both categorical columns in the exercise.\n",
    "Some approaches you can try in this exercise:\n",
    "\n",
    "- use the concept of multicollinearity and remove insignificant variables\n",
    "- use a different method of scaling the numerical variables\n",
    "- use a different ratio of train test split\n",
    "- use the transformation on numerical columns which align it more towards a normal distribution\n",
    "\n",
    "### Get the data\n",
    "\n",
    "We are using the `marketing_customer_analysis.csv` file.\n",
    "\n",
    "### Dealing with the data\n",
    "\n",
    "Already done in rounds 2 to 7.\n",
    "\n",
    "**Bonus**: Build a function, from round 2 and round 7, to clean and process the data.\n",
    "\n",
    "### Explore the data\n",
    "\n",
    "Done in the round 3.\n",
    "\n",
    "### Modeling\n",
    "\n",
    "Description:\n",
    "\n",
    "- Try to improve the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 2 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Quick recap to version control systems: Why git and Github?\n",
    "- Managing a repository on GitHub (quick recap - already discussed on day 1):\n",
    "  - Create a repo\n",
    "  - Make changes and commit to a repo\n",
    "  - Forking and cloning a repo\n",
    "  - Fork vs. clone\n",
    "  - Create a pull request\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 3 key concepts\n",
    "\n",
    "> :clock10: 20 min\n",
    "\n",
    "- Working with branches\n",
    "- Resolving merge conflicts\n",
    "- Adding large files on GitHub\n",
    "- Initializing directories on personal computer as GitHub repos\n",
    "\n",
    "\n",
    "\n",
    "```shell\n",
    "$ git branch \t                        # shows the current branches in the repo\n",
    "$ git branch -a \t                    # shows all branches (even the ones you haven't worked on)\n",
    "$ git checkout -b <NameOfNewBranch>\t  # creates new branch\n",
    "$ git checkout <BranchName> \t        # switches to the branch we want to work on\n",
    "$ git pull \t                          # pulls the latest changes to the branch we are working on (git pull = git fetch + git merge)\n",
    "$ git fetch \t                        # gets all branches from the repository\n",
    "```\n",
    "\n",
    "#### Merging Branches\n",
    "\n",
    "Case 1: Merges changes in branch to the master file\n",
    "\n",
    "```shell\n",
    "$ git checkout master\n",
    "$ git merge <Name of Branch to be merged to Master>\n",
    "```\n",
    "\n",
    "Case 2: Merges changes in master file to the branch\n",
    "\n",
    "```shell\n",
    "$ git checkout <branch name>\n",
    "$ git merge master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### :pencil2: Practice on key concepts - Lab\n",
    "\n",
    "> :clock10: 30 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Final Round\n",
    "\n",
    "For this lab, we still keep using the `marketing_customer_analysis.csv` file that you can find in the `files_for_lab_final` folder.\n",
    "\n",
    "It's time to put it all together. Remember the previous rounds and follow the steps as shown in previous lectures.\n",
    "\n",
    "### 01 - Problem (case study)\n",
    "\n",
    "- Data Description.\n",
    "- Goal.\n",
    "\n",
    "### 02 - Getting Data\n",
    "\n",
    "- Read the `.csv` file.\n",
    "\n",
    "### 03 - Cleaning/Wrangling/EDA\n",
    "\n",
    "- Change headers names.\n",
    "- Deal with NaN values.\n",
    "- Categorical Features.\n",
    "- Numerical Features.\n",
    "- Exploration.\n",
    "\n",
    "### 04 - Processing Data\n",
    "\n",
    "- Dealing with outliers.\n",
    "- Normalization.\n",
    "- Encoding Categorical Data.\n",
    "- Splitting into train set and test set.\n",
    "\n",
    "### 05 - Modeling\n",
    "\n",
    "- Apply model.\n",
    "\n",
    "### 06 - Model Validation\n",
    "\n",
    "- R2.\n",
    "- MSE.\n",
    "- RMSE.\n",
    "- MAE.\n",
    "\n",
    "### 07 - Reporting\n",
    "\n",
    "- Present results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to Lab: Custumer Analysis Final Round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='magenta'>\n",
    "Please comment before each cell of code using a markdown cell. You should clearly state with your own words what the portion of code in the cell bellow does or add other insightful comments on that operation. Use the html tags in this cell to add your comments in a striking color for an easy review.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 - Problem (case study)\n",
    "\n",
    "Data Description.\n",
    "\n",
    "- **customer:** Customer ID\n",
    "- **state:** US State\n",
    "- **customer_lifetime_value:** CLV is the client economic value for a company during all their relationship\n",
    "- **response:** Response to marketing calls (customer engagement)\n",
    "- **coverage:** Customer coverage type\n",
    "- **education:** Customer education level\n",
    "- **effective_to_date:** Effective to date\n",
    "- **employmentstatus:** Customer employment status\n",
    "- **gender:** Customer gender\n",
    "- **income:** Customer income\n",
    "- **location_code:** Customer living zone\n",
    "- **marital_status:** Customer marital status\n",
    "- **monthly_premium_auto:** Monthly premium\n",
    "- **months_since_last_claim:** Last customer claim\n",
    "- **months_since_policy_inception:** Policy Inception\n",
    "- **number_of_open_complaints:** Open claims\n",
    "- **number_of_policies:** Number policies\n",
    "- **policy_type:** Policy type\n",
    "- **policy:** Policy\n",
    "- **renew_offer_type:** Renew\n",
    "- **sales_channel:** Sales channel (customer-company first contact)\n",
    "- **total_claim_amount:** Claims amount\n",
    "- **vehicle_class:** Vehicle class\n",
    "- **vehicle_size:** Vehicle size\n",
    "- **vehicle_type:** Vehicle type\n",
    "\n",
    "**Goal.**  \n",
    "Can we predict the amount claimed by a client?\n",
    "\n",
    "### 02 - Getting Data\n",
    "\n",
    "- Read `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                           # panel data, handling dataframes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./files_for_lab_final/csv_files/marketing_customer_analysis.csv')    # import csv file\n",
    "data.head()                                                    # show first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 - Cleaning/Wrangling/EDA\n",
    "\n",
    "- Change headers names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape       # dataframe dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns     # columns headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=[e.lower().replace(' ', '_') for e in data.columns]   # lower and replace\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deal with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(memory_usage='deep')   # dataframe info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()     # missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['vehicle_class', 'customer'])   # drop useless columns (no info or nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()   # drop rows with nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns.tolist():         # know the unique values for each column\n",
    "    print(c, len(data[c].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Datetime Features.\n",
    "\n",
    "**Effective To Date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original dtype: {data['effective_to_date'].dtype}\\n\")   # object\n",
    "data['effective_to_date']=pd.to_datetime(data['effective_to_date'])   # datetime\n",
    "print(f\"Meantime dtype: {data['effective_to_date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--')\n",
    "print(f\"Min date: {data['effective_to_date'].min()}\")         # from January 1st..\n",
    "print(f\"Max date: {data['effective_to_date'].max()}\")         # to February 28th\n",
    "print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['effective_to_date']=data['effective_to_date'].apply(lambda x: x.toordinal())   # you can change the type to ordinal.\n",
    "\n",
    "print(f\"New dtype: {data['effective_to_date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or alternatively use Unix time\n",
    "# data['effective_to_date']  = (data['effective_to_date']  - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical Features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Values for each class in categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=[col for col in data.columns if (data[col].dtype==object)]     # categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical Features:', len(cat_cols))\n",
    "print('----------')\n",
    "for c in cat_cols:\n",
    "    print(f'Name: {data[c].name}')    # column name\n",
    "    print(f'Type: {data[c].dtype}')   # column type\n",
    "    print(f'Unique values: {len(data[c].unique())}')   # column unique values\n",
    "    print(data[c].unique())\n",
    "    print(((data[c].value_counts()/ sum(data[c].value_counts()))*100))   # percentage\n",
    "    print('\\n----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numerical Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()     # stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=[c for c in data.columns if (data[c].dtype!='object') and (c!='Effective To Date')]   # numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exploration.\n",
    "\n",
    "**Bar plot for each categorical variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # visualization library\n",
    "%matplotlib inline\n",
    "\n",
    "for c in cat_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(data[c].unique(), data[c].value_counts())\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns                           # visualization library, extends plt\n",
    "sns.set(style=\"white\")                          # style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # numerical python, algebra library\n",
    "\n",
    "\n",
    "corr=data.corr()      # compute the correlation matrix\n",
    "\n",
    "\n",
    "mask=np.triu(np.ones_like(corr, dtype=np.bool))     # generate a mask for the upper triangle\n",
    "\n",
    "f, ax=plt.subplots(figsize=(11, 9))                 # set up the matplotlib figure\n",
    "\n",
    "cmap=sns.diverging_palette(220, 10, as_cmap=True)   # generate a custom diverging colormap\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap,             # draw the heatmap with the mask and correct aspect ratio\n",
    "            vmax=.3, center=0, square=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All variables**\n",
    "(be careful, this command may be quite memory hungry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data[num_cols]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar plot for each numerical variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.hist(data[c])\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box plot for each numerical variable for know outliers of each feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.boxplot(data[c])\n",
    "    plt.title(c)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show a plot of the total number of response.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('response', data=data)\n",
    "plt.ylabel('Total number of Response')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show a plot of the response rate by sales channel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot('response', hue='sales_channel', data=data)\n",
    "plt.ylabel('Response by Sales Channel')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show a plot of the response rate by total claim amount.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y='total_claim_amount' , x='response', data=data)\n",
    "plt.ylabel('Response by Total Claim Amount')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show a plot of the response rate by income.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(y='income' , x='response', data=data)\n",
    "plt.ylabel('Response by Inncome')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 - Processing Data\n",
    "\n",
    "- Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. 3*IQR in a column\n",
    "\n",
    "q1=np.percentile(data['customer_lifetime_value'], 25)   # percentile 25\n",
    "q3=np.percentile(data['customer_lifetime_value'], 75)   # percentile 75\n",
    "\n",
    "iqr=q3-q1  # IQR\n",
    "\n",
    "upper=q3+3*iqr   # upper boundary\n",
    "lower=q1-3*iqr   # lower boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['customer_lifetime_value']<lower])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['customer_lifetime_value']>upper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization\n",
    "\n",
    "**Min-Max Scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data['effective_to_date']=MinMaxScaler().fit_transform(data['effective_to_date'].values.reshape(-1, 1))\n",
    "\n",
    "data['effective_to_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in num_cols[:-1]:   # we'll normalize all less the target column\n",
    "    data[c]=StandardScaler().fit_transform(data[c].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Encoding Categorical Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data=pd.get_dummies(data[cat_cols], drop_first=True)   # one hot encoding categorical variables\n",
    "\n",
    "one_hot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat numerical and categorical DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data, one_hot_data], axis=1)   # concat dataframes\n",
    "data.drop(columns=cat_cols, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting into train set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, split X-y (learning-target data)\n",
    "X=data.drop(columns=['total_claim_amount'])\n",
    "y=data['total_claim_amount']\n",
    "\n",
    "# checking shape\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split (4 sets)\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)  # random state fixed sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 - Modeling\n",
    "\n",
    "We have now the data prepared for the modeling phase.\n",
    "https://s3.amazonaws.com/assets.datacamp.com/email/other/ML+Cheat+Sheet_2.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a linear model, which means it works really nicely when the data has a linear shape. But, when the data has a non-linear shape, then a linear model cannot capture the non-linear features.\n",
    "\n",
    "So in this case, you can use the tree-based methods, which do a better job at capturing the non-linearity in the data by dividing the space into smaller sub-spaces depending on the questions asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "linreg=LinReg()    # model\n",
    "linreg.fit(X_train, y_train)   # model train\n",
    "y_pred_linreg=linreg.predict(X_test)   # model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso       # L1\n",
    "from sklearn.linear_model import Ridge       # L2\n",
    "from sklearn.linear_model import ElasticNet  # L1+L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso L1\n",
    "\n",
    "lasso=Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge L2\n",
    "\n",
    "ridge=Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet L1+L2\n",
    "\n",
    "elastic=ElasticNet()\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_elastic = elastic.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "rfr=RFR()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rfr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor as XGBR\n",
    "\n",
    "xgbr=XGBR()\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgbr = xgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "\n",
    "lgbmr=LGBMR()\n",
    "lgbmr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbmr = lgbmr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06 - Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[linreg, lasso, ridge, elastic, rfr, xgbr, lgbmr]\n",
    "model_names=['linreg', 'lasso', 'ridge', 'elastic', 'rfr', 'xgbr', 'lgbmr']\n",
    "preds=[y_pred_linreg, y_pred_lasso, y_pred_ridge, y_pred_elastic, y_pred_rfr, y_pred_xgbr, y_pred_lgbmr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "\n",
    "    train_score=models[i].score(X_train, y_train) #R2\n",
    "    test_score=models[i].score(X_test, y_test)\n",
    "\n",
    "    print ('Model: {}, train R2: {} -- test R2: {}'.format(model_names[i], train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "for i in range(len(models)):\n",
    "\n",
    "    train_mse=mse(models[i].predict(X_train), y_train) #MSE\n",
    "    test_mse=mse(preds[i], y_test)\n",
    "\n",
    "    print ('Model: {}, train MSE: {} -- test MSE: {}'.format(model_names[i], train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RMSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "\n",
    "    train_rmse=mse(models[i].predict(X_train), y_train)**0.5 #RMSE\n",
    "    test_rmse=mse(preds[i], y_test)**0.5\n",
    "\n",
    "    print ('Model: {}, train RMSE: {} -- test RMSE: {}'.format(model_names[i], train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "for i in range(len(models)):\n",
    "    train_mae=mae(models[i].predict(X_train), y_train) #MAE\n",
    "    test_mae=mae(preds[i], y_test)\n",
    "\n",
    "    print ('Model: {}, train MAE: {} -- test MAE: {}'.format(model_names[i], train_mae, test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you try to improve the model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I.e. you can try by removing columns that you feel are not predictive. Or making transformations to some columns to make them closer to a normal distribution, or..\n",
    "\n",
    "    - Choosing a different way to fill null values\n",
    "    - Working with a categorical variable to reduce the number of categories\n",
    "    - Different data transformation\n",
    "    - A different method to remove outliers\n",
    "    - Choosing different scaling method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='magenta'>\n",
    "Your code goes here:\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07 - Reporting\n",
    "\n",
    "- Present results.\n",
    "\n",
    "**Data Level**\n",
    "\n",
    "- Drop Nan values because they are, in fact, duplicates.\n",
    "- Do not drop outliers because they are just a few.\n",
    "\n",
    "**Problem Level**\n",
    "\n",
    "- Total claim amount has a great variance.\n",
    "- We can predict the total claim amount with a 25% of error, even when R2 is high.\n",
    "- We need to determinate which are the significative variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "- [Best practices for PowerPoint presentations](https://alum.mit.edu/best-practices-powerpoint-presentations)\n",
    "- [More tips on PowerPoint formatting](https://www.workfront.com/blog/10-tips-for-designing-presentations-that-dont-suck-part-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
