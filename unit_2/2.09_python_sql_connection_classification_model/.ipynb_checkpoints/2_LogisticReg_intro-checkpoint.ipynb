{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model - Logistic Regression\n",
    "\n",
    "\n",
    "**Assumptions of logistic regression model**\n",
    "  \n",
    "- No free lunch theorem - No model comes without certain assumptions. If the assumptions of the model are not met, it will have adverse effects on the mode. Understanding those assumptions helps us with data cleaning and pre-processing methods.\n",
    "\n",
    "- Some assumptions that are not required in the logistic regression model (but are important for linear regression):\n",
    "\n",
    "      - It does not require a linear relationship between the dependent and independent variables.\n",
    "      - The error terms (residuals) do not need to be normally distributed.\n",
    "      - It makes no assumption about the distribution of independent variables.\n",
    "      - Homoscedasticity / Homogeneity of variance is not required (Optional - If the instructor wants to talk more about it).\n",
    "\n",
    "\n",
    "**Homoscedasticity / Homogeneity of variance**\n",
    "\n",
    "For linear regression, Homoscedasticity is talked about in terms of residuals (errors). If the variance of the residuals is the same around the regression line, then the points are homoscedastic and the assumption is followed. If the variance of the residuals is varying, then the points are heteroscedastic. The residuals can also be checked with the independent variables and should display the same behavior. The figure below shows the concept.\n",
    "\n",
    "![Homoscedasticity](https://education-team-2020.s3-eu-west-1.amazonaws.com/data-analytics/2.9-homoscedasticity.png)\n",
    "\n",
    "Implications if the assumption is not met are:\n",
    "\n",
    "1. With linear regression, the _OLS_ method is used to minimize the residuals/errors. By default, it gives equal weight to all the observations. But if heteroscedasticity is present, the cases with larger disturbance/variance have more pull on the regression line.\n",
    "2. Heteroscedasticity also means that the residuals are biased which is a problem for other statistical tests (ANOVA, tests for significance) and calculating confidence intervals.\n",
    "\n",
    "Dealing with heteroscedasticity\n",
    "\n",
    "1. Instead of _OLS_, weighted least squares can be used.\n",
    "2. Transformation of the dependent variable using one of the variances stabilizing transformations can be done (square root transformation, logarithmic transformation)\n",
    "\n",
    "\n",
    "- Some of the other assumptions of the logistic regression model are mentioned here:\n",
    "\n",
    "      - Dependent variable structure - For binary logistic regression, the dependent variable should be binary.\n",
    "      - Observation independence - The observations should be independent of each other ie they should not come from repeated measurements.\n",
    "      - Absence of multicollinearity - There should be little or no multi-collinearity between the independent variables.\n",
    "      - The linearity of independent variables and log odds - The independent variables should be linearly dependent on **log odds**.\n",
    "      - Large sample size - You need a minimum of 10 cases with the least frequent outcome for each independent variable in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
