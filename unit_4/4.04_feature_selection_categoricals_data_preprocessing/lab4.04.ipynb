{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220a0dfe-a2cf-423c-8298-d9e3a8c10a01",
   "metadata": {},
   "source": [
    "# Lab | Data cleaning and wrangling\n",
    "\n",
    "For this lab, we will be using the same dataset we used in the previous labs. We recommend using the same notebook since you will be reusing the same variables you previous created and used in labs. \n",
    "\n",
    "### Instructions\n",
    "\n",
    "So far we have worked on `EDA`. This lab will focus on data cleaning and wrangling from everything we noticed before.\n",
    "\n",
    "1. We will start with removing outliers. So far, we have discussed different methods to remove outliers. Use the one you feel more comfortable with, define a function for that. Use the function to remove the outliers and apply it to the dataframe.\n",
    "2. Create a copy of the dataframe for the data wrangling.\n",
    "3. Normalize the continuous variables. You can use any one method you want.\n",
    "4. Encode the categorical variables\n",
    "5. The time variable can be useful. Try to transform its data into a useful one. Hint: Day week and month as integers might be useful.\n",
    "6. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.\n",
    "\n",
    "**Hint for Categorical Variables**\n",
    "\n",
    "- You should deal with the categorical variables as shown below (for ordinal encoding, dummy code has been provided as well):\n",
    "\n",
    "```python\n",
    "# One hot to state\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class\n",
    "# Ordinal vehicle size\n",
    "\n",
    "data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "# given that column \"coverage\" in the dataframe \"data\" has three categories:\n",
    "# \"basic\", \"extended\", and \"premium\" and values are to be represented in the same order.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040843e2-bd8b-4cfa-9253-787c15ca9e41",
   "metadata": {},
   "source": [
    "### LAB Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5bcb38-0275-49f6-acf2-99ac9524b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No NaNs so just remove outliers (normalization method)\n",
    "def outliers(column, threshold = 3):\n",
    "    \"\"\"\n",
    "    docs\n",
    "    \"\"\"\n",
    "\n",
    "    data = column[abs(column.apply(lambda x: (x - column.mean()) / column.var() ** (1/2))) > threshold]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737ffe8c-6652-47bc-8d14-dd8d63beba94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CLV_outliers \u001b[38;5;241m=\u001b[39m outliers(\u001b[43mcustomer_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustomer_lifetime_value\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      2\u001b[0m MPA_outliers \u001b[38;5;241m=\u001b[39m outliers(customer_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonthly_premium_auto\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'customer_df' is not defined"
     ]
    }
   ],
   "source": [
    "CLV_outliers = outliers(customer_df[\"customer_lifetime_value\"])\n",
    "MPA_outliers = outliers(customer_df[\"monthly_premium_auto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb83d6b-636b-4e3e-b94f-11e197987916",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = CLV_outliers.index | MPA_outliers.index # Union\n",
    "clean_customer_df = customer_df.drop(to_drop).reset_index(drop = True)\n",
    "clean_customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5816032-b789-4f33-95be-a781c0a66bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_customer_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_copy \u001b[38;5;241m=\u001b[39m \u001b[43mclean_customer_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_customer_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_copy = clean_customer_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "babb03d7-ff44-4d8e-ab50-da40b2213f42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'continuous' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Normalizing continuous variables (but target)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcontinuous\u001b[49m\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonths_since_policy_inception\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m continuous\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_claim_amount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cont_var \u001b[38;5;129;01min\u001b[39;00m continuous:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'continuous' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalizing continuous variables (but target)\n",
    "\n",
    "continuous.remove(\"months_since_policy_inception\")\n",
    "continuous.remove(\"total_claim_amount\")\n",
    "for cont_var in continuous:\n",
    "    maximum = clean_customer_df[cont_var].max()\n",
    "    minimum = clean_customer_df[cont_var].min()\n",
    "    clean_customer_df[cont_var] = clean_customer_df[cont_var].apply(lambda x: (x - minimum) / (maximum - minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41829437-ac6a-4d77-aaad-df7093b14ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv(\"WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\")\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8e75f1a-e134-424e-9314-aa01f918df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "153be3e0-a05b-4c7a-9975-23556916de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c0ce5-4883-4999-915d-59f84c698e51",
   "metadata": {},
   "source": [
    "**REMEMBER**\n",
    "\n",
    "- Education, employment status, policy, and vehicle class are somewhat unbalanced.\n",
    "- For education, we could turn it into a binary variable (`college +-`), but I wouldn't touch it.\n",
    "- The policy is redundant, maybe we can classify it in `L1`, `L2` and `L3` groups.\n",
    "- Id concatenates luxury SUV, sports car and luxury car into luxury or among the other classes.\n",
    "- For employment, we could divide them among employed, unemployed and inactive.\n",
    "- We can see that having open complaints isn't that common, so we can turn it into a binary variable, open - not open.\n",
    "- For the number of policies, we could join use 1, 2, 3, 4+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2a9d5f8-77ef-44a6-9559-f2b7a1f452a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "# One hot to state\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class\n",
    "# Ordinal vehicle size\n",
    "```\n",
    "\n",
    "```python\n",
    "customer_df.isna().sum()/len(customer_df)\n",
    "clean_customer_df[\"education\"] = clean_customer_df[\"education\"].apply(lambda x: \"Graduate\" if x in [\"Master\", \"Doctor\"] else x)\n",
    "inactive = [\"Medical Leave\", \"Disabled\", \"Retired\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4af9ba4-090f-4252-bc4a-b25cb9fceb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_customer_df[\"employmentstatus\"] = clean_customer_df[\"employmentstatus\"].apply(lambda x: \"Inactive\" if x in inactive else x)\n",
    "clean_customer_df[\"gender\"] = clean_customer_df[\"gender\"].apply(lambda x: 1 if x == \"F\" else 0)\n",
    "clean_customer_df[\"policy\"] = clean_customer_df[\"policy\"].apply(lambda x: x[-2:])\n",
    "luxury = [\"Sports Car\", \"Luxury SUV\", \"Luxury Car\"]\n",
    "clean_customer_df[\"vehicle_class\"] = clean_customer_df[\"vehicle_class\"].apply(lambda x: \"Luxury\" if x in luxury else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "423af496-4fb9-4355-9920-3fc70695e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy\n",
    "final_df = clean_customer_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20d1b98f-7aa5-4dd5-8414-19e9f77d16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop customer (id)\n",
    "ordinal = clean_customer_df.drop(columns = \"customer\")\n",
    "ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beb483e2-f150-411c-89d3-e032abfb2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoders\n",
    "# Ordinal to coverage\n",
    "# Ordinal to employmentstatus\n",
    "# Ordinal to location code\n",
    "# Ordinal vehicle size\n",
    "\n",
    "ordinal[\"coverage\"] = ordinal[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})\n",
    "ordinal[\"employmentstatus\"] = ordinal[\"employmentstatus\"].map({\"Unemployed\" : 0, \"Inactive\" : 1, \"Employed\" : 2})\n",
    "ordinal[\"location_code\"] = ordinal[\"location_code\"].map({\"Rural\" : 0, \"Suburban\" : 1, \"Urban\" : 2})\n",
    "ordinal[\"vehicle_size\"] = ordinal[\"vehicle_size\"].map({\"Small\" : 0, \"Medsize\" : 1, \"Large\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "019068c7-c70a-46dd-be34-2182395fe914",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ordinal.copy()\n",
    "one_hot_colums = final_df.select_dtypes(include = object).columns[1:]\n",
    "one_hot_colums\n",
    "\n",
    "# One hot encoders\n",
    "\n",
    "# One hot to state\n",
    "# One hot to marital status\n",
    "# One hot to policy type\n",
    "# One hot to policy\n",
    "# One hot to renew offercustomer_df\n",
    "# One hot to sales channel\n",
    "# One hot vehicle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59bc9938-de4c-41ed-8cb8-3ff856867638",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(one_hot, columns = one_hot_colums)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eaafb8ca-38b0-43a6-85fd-aa5f75532131",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-6487d42a2285>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"effective_to_date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "final_df = one_hot.copy()\n",
    "final_df[\"day\"] = time_df[\"day\"]\n",
    "final_df[\"week\"] = time_df[\"week\"]\n",
    "final_df[\"month\"] = time_df[\"month\"]\n",
    "final_df = final_df.drop(columns = \"effective_to_date\")\n",
    "final_df.apply(pd.to_numeric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
